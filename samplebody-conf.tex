
\section{Motivation}

As a software engineers,
we often came across software destributed
in a form of docker containers alongside
of traditional binary files,
or articles comparing docker to the other kind of virtualization techniques,
or DevOps research papers comparing the performance of cloud instances in AWS,
but did not know what it is about.
Main goal of this research for us is to provide an answer
for an important question, whether it is worth
to change our infrastructures
from virtualized hardware to Docker, or stick to KVM, for example.

\section{Introduction}

Virtualization was very important for the industry at the time of its invention in the mid-2000.
Smart virtualization engines such as Linux-based QEMU, KVM, Xen and their Windows-based rival Hyper-V changed the IT industry forever,
sufficiently decreasing the need for dedicated and local hardware.

This shift has made a cloud computing from abstract theory to the reality,
creating huge benefits for cloud providers like Amazon AWS, Microsoft Azure and Google.
However, the virtualization was not perfect, as any advanced technology:
as obvious as their advantages were,
it had many drawbacks mainly in maintenance of the complicated virtualized infrastructure.

With the first release of its state-of-the-art Docker library for Linux,
developer Solomon Hikes tried to provide its own way of solving these problems,
based on the microservice architecture, which has become not only a successful startup
with capitalization of over two billions USD as of October 2017,
but also a major breakthrough in the IT Field, almost pushing the existing
businesses and startups in maintaining advanced virtualized infrastructure
to the edge of survival or even completely eliminating them from the market for good.

\section{Long way to Docker}

Some technologies evolved itself from the existing ideas or approach at the time of invention, and Docker is no exclusion.
The aim of this section is to provide an overview of main competitive
technologies referenced as industry standardards before the era of Docker, their advantages and disadvantages.

\subsection{Traditional architecture}

Traditional architecture was an industry standard before mid-2000s.
A traditional server is just a hardware unit which has an operating system installed,
which then supervises application running.

Though perfectly well suitable for normal user, this architecture has proven itself as unreliable, non-scalable,
and generally not suitable for long-term enterprise environments support.

The operating system layer was usually installed manually or with installation scripts specially written for that purpose,
and the enterprise application running inside these environments were configured from within the OS by the system administrators.

\subsection{Virtualization}
Virtualization is a technology of clear and safe dividing
of existing hardware resources amongst the "host" operating system,
which has a direct access to the hardware resources and where the virtualization program is started, and some of the "guest" operating systems,
which lifecycle is maintained and supervised by the abovementioned software.
With the invention of the virtualization first as software solution,
it has become possible for one server to serve multiple users at a time significantly decreasing stall times and the need for excessive hardware.
Moreover, it became possible to sell the unused
server power to the other commercial entities or private customers,
bringing additional profit to the organization.



\subsection{Paravirtualization}


Online citations: \cite{TUGInstmem, Thornburg01, CTANacmart}.



\subsection{Unsolved problems of the virtualization}


With the brilliance of these technologies as it is, some of the problems never found it solutions completely:

First of all, all of the virtual systems need to be updated regularly, not only for the obvious reason of security,but also for the sake of prolonged maintaining of deployed applications.

Second, all the virtualized infrastructure had the need to be backed up regularly to prevent the loss of important business information.

With the complexity of the infrastructures growing exponentially, the need for additional employments made an impact on the industry



\section{Docker principles}

\subsection{Definition of a container}

Container is another type of virtualization approach.
Containers and virtual machines have similar resource isolation and allocation benefits,
but function differently because containers virtualize the operating system instead of hardware.
Containers are more portable and efficient, as can be seen on the picture 3.

\subsection{Docker architecture}

Docker is a software product consisting mainly of a library written in Go programming language which acts as an intermediary between apps packaged in the container and the Linux kernel.
To achieve its task, the following parts of Linux kernel is used:
cgroups
SELinux
namespaces
Netlink
AppArmor
capabilities
Moreover, the docker library is able to determine when multiple container applications share the same libraries and provide it for them at the time needed.
That way
The main advantage of Docker is that it uses already existing features provided by the Linux operating system.

\subsubsection{Docker Image}

To use docker, a docker image ought to be created. An image is compiled by docker engine itself, using a script file provided by user called Dockerfile. One of the most powerful features of docker is inheritance, so usual approach in the industry is to create a base image and extend it with new features later when there is such a necessity.
A base image is extended using FROM directive like this:
FROM: ubuntu 16.10
Using the RUN directive, different commands supported by the base operating system can be passed to the container for setting up the image like this:
RUN sudo apt-get install mariadb
Moreover, the files needed by the applications can be copied directly into the image using the COPY directive:

\subsubsection{Using a container}

Once an image is created, it can be deployed into a container. A
container in terms of docker is nothing more than a running
instance of Host OS, where the docker is installed. It can be placed
in the cloud or on the local hardware.
Created containers can be launched, stopped, and queried for their
current state for maintenance work at will, exactly like normal virtual
machine can be. Upon container creation it is possible to pass
different launch parametres like an automatic restart if the server
has been turned off by some reason.

\subsubsection{Union file system}

While proven to reduce average CPU load and memory usage by
eliminating the redundant duplication of the OS components of the
virtual environments,
unionfs (Union File System, further referred as UFS), a file system
initially developed by and further maintained by the open source
community, is one of the most crucial parts of docker system.
UFS consits of “layers”, abstract file system units clearly separated
from each other, with some of them write-protected. This allows
docker core to maintain one and the only copy of the operating
system files necessary for its working declaring it unchangeable
while keeping the changeable files belonging to different images
unreachable from within other layers thus making it impossible to
alter or delete them, drastically improving the security of the virtual
environments.

\subsubsection{Container registry}

\subsubsection{Container interaction}


\section{Conclusions}
This paragraph will end the body of this sample document.
Remember that you might still have Acknowledgments or
Appendices; brief samples of these
follow.  There is still the Bibliography to deal with; and
we will make a disclaimer about that here: with the exception
of the reference to the \LaTeX\ book, the citations in
this paper are to articles which have nothing to
do with the present subject and are used as
examples only.
%\end{document}  % This is where a 'short' article might terminate



\appendix
%Appendix A
\section{Headings in Appendices}
The rules about hierarchical headings discussed above for
the body of the article are different in the appendices.
In the \textbf{appendix} environment, the command
\textbf{section} is used to
indicate the start of each Appendix, with alphabetic order
designation (i.e., the first is A, the second B, etc.) and
a title (if you include one).  So, if you need
hierarchical structure
\textit{within} an Appendix, start with \textbf{subsection} as the
highest level. Here is an outline of the body of this
document in Appendix-appropriate form:
\subsection{Introduction}
\subsection{The Body of the Paper}
\subsubsection{Type Changes and  Special Characters}
\subsubsection{Math Equations}
\paragraph{Inline (In-text) Equations}
\paragraph{Display Equations}
\subsubsection{Citations}
\subsubsection{Tables}
\subsubsection{Figures}
\subsubsection{Theorem-like Constructs}
\subsubsection*{A Caveat for the \TeX\ Expert}
\subsection{Conclusions}
\subsection{References}
Generated by bibtex from your \texttt{.bib} file.  Run latex,
then bibtex, then latex twice (to resolve references)
to create the \texttt{.bbl} file.  Insert that \texttt{.bbl}
file into the \texttt{.tex} source file and comment out
the command \texttt{{\char'134}thebibliography}.
% This next section command marks the start of
% Appendix B, and does not continue the present hierarchy
\section{More Help for the Hardy}

Of course, reading the source code is always useful.  The file
\path{acmart.pdf} contains both the user guide and the commented
code.

\begin{acks}
  The authors would like to thank Dr. Yuhua Li for providing the
  MATLAB code of the \textit{BEPS} method.

  The authors would also like to thank the anonymous referees for
  their valuable comments and helpful suggestions. The work is
  supported by the \grantsponsor{GS501100001809}{National Natural
    Science Foundation of
    China}{http://dx.doi.org/10.13039/501100001809} under Grant
  No.:~\grantnum{GS501100001809}{61273304}
  and~\grantnum[http://www.nnsf.cn/youngscientists]{GS501100001809}{Young
    Scientists' Support Program}.

\end{acks}
